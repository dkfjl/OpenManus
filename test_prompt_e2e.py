"""
æç¤ºè¯åº“ E2E æµ‹è¯•è„šæœ¬
æµ‹è¯• Agent å·¥å…·è°ƒç”¨å’Œ /run æ¥å£çš„ prompt æ³¨å…¥åŠŸèƒ½
"""

import sys
import asyncio
from fastapi.testclient import TestClient

# å¯¼å…¥ FastAPI åº”ç”¨å’Œç›¸å…³æ¨¡å—
from app.app import app
from app.tool.prompt_library import PromptLibraryTool
from app.services.prompt_service import PromptService

# åˆ›å»ºæµ‹è¯•å®¢æˆ·ç«¯
client = TestClient(app)

# æµ‹è¯•ç”¨æˆ·ID
TEST_USER = "e2e_test_user"


def setup_test_data():
    """å‡†å¤‡æµ‹è¯•æ•°æ®ï¼šåˆ›å»ºä¸€ä¸ªä¸ªäººæç¤ºè¯"""
    print("\nğŸ“¦ å‡†å¤‡æµ‹è¯•æ•°æ®...")

    response = client.post(
        "/console/api/prompts",
        json={
            "name": "E2Eæµ‹è¯•æ¨¡æ¿",
            "description": "ç”¨äºE2Eæµ‹è¯•çš„æç¤ºè¯æ¨¡æ¿",
            "prompt": "ä½ æ˜¯{role}ï¼Œä½ çš„ä»»åŠ¡æ˜¯{task}ã€‚è¯·ç¡®ä¿{requirement}ã€‚",
            "ownerId": TEST_USER
        },
        headers={"X-User-Id": TEST_USER}
    )

    assert response.status_code == 201, f"åˆ›å»ºæµ‹è¯•æ•°æ®å¤±è´¥: {response.text}"
    data = response.json()
    prompt_id = data["data"]["id"]

    print(f"   âœ… æµ‹è¯•æ•°æ®å·²åˆ›å»ºï¼ŒID: {prompt_id}")
    return prompt_id


def cleanup_test_data(prompt_id):
    """æ¸…ç†æµ‹è¯•æ•°æ®"""
    print("\nğŸ§¹ æ¸…ç†æµ‹è¯•æ•°æ®...")

    response = client.delete(
        f"/console/api/prompts/{prompt_id}",
        headers={"X-User-Id": TEST_USER}
    )

    if response.status_code == 200:
        print(f"   âœ… æµ‹è¯•æ•°æ®å·²æ¸…ç†")
    else:
        print(f"   âš ï¸ æ¸…ç†æµ‹è¯•æ•°æ®å¤±è´¥: {response.text}")


async def test_agent_tool_list_recommended():
    """æµ‹è¯• 1: Agent å·¥å…·è°ƒç”¨ - åˆ—å‡ºæ¨èæ¨¡æ¿"""
    print("\nğŸ§ª æµ‹è¯• 1: Agent å·¥å…·è°ƒç”¨ - åˆ—å‡ºæ¨èæ¨¡æ¿")

    tool = PromptLibraryTool()

    result = await tool.execute(
        action="list_recommended",
        page=1,
        page_size=5
    )

    assert result.output is not None, "å·¥å…·è¿”å›ç»“æœä¸ºç©º"
    assert "list_recommended" in result.output, "è¿”å›ç»“æœæ ¼å¼é”™è¯¯"

    print(f"   âœ… æˆåŠŸï¼å·¥å…·è¿”å›: {result.output[:200]}...")


async def test_agent_tool_get_recommended():
    """æµ‹è¯• 2: Agent å·¥å…·è°ƒç”¨ - è·å–æ¨èæ¨¡æ¿è¯¦æƒ…"""
    print("\nğŸ§ª æµ‹è¯• 2: Agent å·¥å…·è°ƒç”¨ - è·å–æ¨èæ¨¡æ¿è¯¦æƒ…")

    # å…ˆè·å–ä¸€ä¸ªæ¨èæ¨¡æ¿çš„ID
    tool = PromptLibraryTool()
    list_result = await tool.execute(action="list_recommended", page=1, page_size=1)

    # ä»ç»“æœä¸­æå–ç¬¬ä¸€ä¸ªID (ç®€åŒ–å¤„ç†)
    import json
    list_data = json.loads(list_result.output)

    if list_data["data"]["items"]:
        prompt_id = list_data["data"]["items"][0]["id"]

        # è·å–è¯¦æƒ…
        detail_result = await tool.execute(
            action="get_prompt",
            prompt_type="recommended",
            prompt_id=prompt_id
        )

        assert detail_result.output is not None, "å·¥å…·è¿”å›ç»“æœä¸ºç©º"
        assert "get_prompt" in detail_result.output, "è¿”å›ç»“æœæ ¼å¼é”™è¯¯"

        print(f"   âœ… æˆåŠŸï¼è·å–åˆ°æ¨¡æ¿ {prompt_id} çš„è¯¦æƒ…")
    else:
        print(f"   âš ï¸ è·³è¿‡ï¼šæ²¡æœ‰å¯ç”¨çš„æ¨èæ¨¡æ¿")


async def test_agent_tool_create_personal():
    """æµ‹è¯• 3: Agent å·¥å…·è°ƒç”¨ - åˆ›å»ºä¸ªäººæç¤ºè¯"""
    print("\nğŸ§ª æµ‹è¯• 3: Agent å·¥å…·è°ƒç”¨ - åˆ›å»ºä¸ªäººæç¤ºè¯")

    import os
    os.environ["CURRENT_USER_ID"] = TEST_USER

    tool = PromptLibraryTool()

    result = await tool.execute(
        action="create_personal",
        name="Agentåˆ›å»ºçš„æç¤ºè¯",
        prompt="è¿™æ˜¯é€šè¿‡ Agent å·¥å…·åˆ›å»ºçš„æç¤ºè¯ï¼Œå†…å®¹åŒ…å«{variable}",
        description="Agent æµ‹è¯•"
    )

    assert result.output is not None, "å·¥å…·è¿”å›ç»“æœä¸ºç©º"
    assert result.error is None, f"å·¥å…·è¿”å›é”™è¯¯: {result.error}"

    # æå–åˆ›å»ºçš„ID
    import json
    data = json.loads(result.output)
    created_id = data["data"]["id"]

    print(f"   âœ… æˆåŠŸï¼åˆ›å»ºçš„ID: {created_id}")

    # æ¸…ç†
    await tool.execute(action="delete_personal", prompt_id=created_id)
    print(f"   âœ… å·²æ¸…ç†æµ‹è¯•æ•°æ®")


async def test_agent_tool_list_personal():
    """æµ‹è¯• 4: Agent å·¥å…·è°ƒç”¨ - åˆ—å‡ºä¸ªäººæç¤ºè¯"""
    print("\nğŸ§ª æµ‹è¯• 4: Agent å·¥å…·è°ƒç”¨ - åˆ—å‡ºä¸ªäººæç¤ºè¯")

    import os
    os.environ["CURRENT_USER_ID"] = TEST_USER

    tool = PromptLibraryTool()

    result = await tool.execute(
        action="list_personal",
        page=1,
        page_size=10
    )

    assert result.output is not None, "å·¥å…·è¿”å›ç»“æœä¸ºç©º"
    assert "list_personal" in result.output, "è¿”å›ç»“æœæ ¼å¼é”™è¯¯"

    print(f"   âœ… æˆåŠŸï¼å·¥å…·è¿”å›: {result.output[:200]}...")


def test_prompt_service_merge_functionality(test_prompt_id):
    """æµ‹è¯• 8: PromptService - å˜é‡æ›¿æ¢å’Œåˆå¹¶åŠŸèƒ½"""
    print("\nğŸ§ª æµ‹è¯• 8: PromptService - å˜é‡æ›¿æ¢å’Œåˆå¹¶åŠŸèƒ½")

    import os
    os.environ["CURRENT_USER_ID"] = TEST_USER

    service = PromptService()

    # æµ‹è¯•å˜é‡æ›¿æ¢
    final_prompt = service.get_and_merge_prompt(
        prompt_type="personal",
        prompt_id=test_prompt_id,
        owner_id=TEST_USER,
        merge_vars={
            "role": "æ•°æ®åˆ†æå¸ˆ",
            "task": "åˆ†æé”€å”®æ•°æ®",
            "requirement": "æä¾›å¯è§†åŒ–å›¾è¡¨"
        },
        additional_prompt="é¢å¤–è¯´æ˜ï¼šé‡ç‚¹å…³æ³¨Q4å­£åº¦æ•°æ®"
    )

    # éªŒè¯å˜é‡æ›¿æ¢
    assert "æ•°æ®åˆ†æå¸ˆ" in final_prompt, "å˜é‡ {role} æœªæ­£ç¡®æ›¿æ¢"
    assert "åˆ†æé”€å”®æ•°æ®" in final_prompt, "å˜é‡ {task} æœªæ­£ç¡®æ›¿æ¢"
    assert "æä¾›å¯è§†åŒ–å›¾è¡¨" in final_prompt, "å˜é‡ {requirement} æœªæ­£ç¡®æ›¿æ¢"
    assert "é¢å¤–è¯´æ˜ï¼šé‡ç‚¹å…³æ³¨Q4å­£åº¦æ•°æ®" in final_prompt, "é™„åŠ promptæœªæ­£ç¡®åˆå¹¶"

    print(f"   âœ… æˆåŠŸï¼å˜é‡æ›¿æ¢å’Œåˆå¹¶æ­£å¸¸å·¥ä½œ")
    print(f"   æœ€ç»ˆprompté•¿åº¦: {len(final_prompt)} å­—ç¬¦")


def test_run_endpoint_with_prompt_id(test_prompt_id):
    """æµ‹è¯• 5: /run æ¥å£ - ä½¿ç”¨ promptId å’Œ mergeVars"""
    print("\nğŸ§ª æµ‹è¯• 5: /run æ¥å£ - promptId æ³¨å…¥å’Œå˜é‡æ›¿æ¢")

    import os
    os.environ["CURRENT_USER_ID"] = TEST_USER

    # æ³¨æ„ï¼šè¿™ä¸ªæµ‹è¯•ä¼šå®é™…è°ƒç”¨ Agentï¼Œå¯èƒ½éœ€è¦å¾ˆé•¿æ—¶é—´
    # åœ¨å®é™…ç¯å¢ƒä¸­å¯èƒ½éœ€è¦ mock run_manus_flow

    # å…ˆæµ‹è¯• schema éªŒè¯
    response = client.post(
        "/run",
        json={
            "promptId": test_prompt_id,
            "promptType": "personal",
            "mergeVars": {
                "role": "æ•°æ®åˆ†æå¸ˆ",
                "task": "åˆ†æé”€å”®æ•°æ®",
                "requirement": "æä¾›å¯è§†åŒ–å›¾è¡¨"
            },
            "prompt": "é¢å¤–è¯´æ˜ï¼šé‡ç‚¹å…³æ³¨Q4å­£åº¦æ•°æ®"
        }
    )

    # ç”±äº /run è·¯ç”±å¯èƒ½æœªåŠ è½½ï¼ˆä¾èµ– daytonaï¼‰ï¼Œæˆ‘ä»¬å…è®¸ 404
    # å¦‚æœè¿”å› 503 æˆ– 409ï¼Œè¯´æ˜æœåŠ¡æ­£å¸¸ä½†æ­£åœ¨åˆå§‹åŒ–æˆ–å¿™ç¢Œ
    if response.status_code == 404:
        print(f"   âš ï¸ è·³è¿‡ï¼š/run è·¯ç”±æœªåŠ è½½ï¼ˆå¯èƒ½ç¼ºå°‘ä¾èµ–æ¨¡å—ï¼‰")
        return

    assert response.status_code in [200, 409, 503], \
        f"çŠ¶æ€ç é”™è¯¯: {response.status_code}\n{response.text}"

    if response.status_code == 200:
        print(f"   âœ… æˆåŠŸï¼/run æ¥å£æ­£å¸¸æ‰§è¡Œ")
        data = response.json()
        print(f"   ç»“æœ: {data.get('result', 'æ— ç»“æœ')[:100]}...")
    elif response.status_code == 409:
        print(f"   âš ï¸ æœåŠ¡å¿™ç¢Œï¼ˆ409ï¼‰ï¼Œä½†è¯·æ±‚æ ¼å¼æ­£ç¡®")
    elif response.status_code == 503:
        print(f"   âš ï¸ æœåŠ¡åˆå§‹åŒ–ä¸­ï¼ˆ503ï¼‰ï¼Œä½†è¯·æ±‚æ ¼å¼æ­£ç¡®")


def test_run_endpoint_with_recommended_prompt():
    """æµ‹è¯• 6: /run æ¥å£ - ä½¿ç”¨æ¨èæ¨¡æ¿"""
    print("\nğŸ§ª æµ‹è¯• 6: /run æ¥å£ - ä½¿ç”¨æ¨èæ¨¡æ¿")

    # å…ˆè·å–ä¸€ä¸ªæ¨èæ¨¡æ¿ID
    response = client.get("/console/api/prompt/overview", params={
        "type": "recommended",
        "page": 1,
        "pageSize": 1
    })

    if response.status_code == 200:
        data = response.json()
        if data.get("items"):
            recommended_id = data["items"][0]["id"]

            # ä½¿ç”¨æ¨èæ¨¡æ¿
            run_response = client.post(
                "/run",
                json={
                    "promptId": recommended_id,
                    "promptType": "recommended",
                    "prompt": "è¯·ç®€å•å›ç­”"
                }
            )

            # å¦‚æœ /run è·¯ç”±æœªåŠ è½½ï¼Œè·³è¿‡
            if run_response.status_code == 404:
                print(f"   âš ï¸ è·³è¿‡ï¼š/run è·¯ç”±æœªåŠ è½½ï¼ˆå¯èƒ½ç¼ºå°‘ä¾èµ–æ¨¡å—ï¼‰")
                return

            assert run_response.status_code in [200, 409, 503], \
                f"çŠ¶æ€ç é”™è¯¯: {run_response.status_code}\n{run_response.text}"

            print(f"   âœ… æˆåŠŸï¼æ¨èæ¨¡æ¿ {recommended_id} å¯ä»¥æ­£å¸¸ä½¿ç”¨")
        else:
            print(f"   âš ï¸ è·³è¿‡ï¼šæ²¡æœ‰å¯ç”¨çš„æ¨èæ¨¡æ¿")
    else:
        print(f"   âš ï¸ è·³è¿‡ï¼šæ— æ³•è·å–æ¨èæ¨¡æ¿åˆ—è¡¨")


def test_run_endpoint_validation():
    """æµ‹è¯• 7: /run æ¥å£ - å‚æ•°éªŒè¯"""
    print("\nğŸ§ª æµ‹è¯• 7: /run æ¥å£ - å‚æ•°éªŒè¯")

    # æµ‹è¯•ï¼šä½¿ç”¨ä¸å­˜åœ¨çš„ promptId
    response = client.post(
        "/run",
        json={
            "promptId": "non-existent-id-12345",
            "promptType": "personal"
        }
    )

    # å¦‚æœ /run è·¯ç”±æœªåŠ è½½ï¼Œè·³è¿‡
    if response.status_code == 404:
        print(f"   âš ï¸ è·³è¿‡ï¼š/run è·¯ç”±æœªåŠ è½½ï¼ˆå¯èƒ½ç¼ºå°‘ä¾èµ–æ¨¡å—ï¼‰")
        return

    assert response.status_code == 400, \
        f"åº”è¯¥è¿”å› 400ï¼Œå®é™…: {response.status_code}"

    print(f"   âœ… æˆåŠŸï¼æ­£ç¡®æ‹’ç»ä¸å­˜åœ¨çš„ promptId")


async def run_all_e2e_tests():
    """æ‰§è¡Œæ‰€æœ‰ E2E æµ‹è¯•"""
    print("=" * 60)
    print("ğŸš€ å¼€å§‹ E2E æµ‹è¯•")
    print("=" * 60)

    test_prompt_id = None

    try:
        # å‡†å¤‡æµ‹è¯•æ•°æ®
        test_prompt_id = setup_test_data()

        # Agent å·¥å…·è°ƒç”¨æµ‹è¯•
        await test_agent_tool_list_recommended()
        await test_agent_tool_get_recommended()
        await test_agent_tool_create_personal()
        await test_agent_tool_list_personal()

        # PromptService åŠŸèƒ½æµ‹è¯•
        test_prompt_service_merge_functionality(test_prompt_id)

        # /run æ¥å£æµ‹è¯•ï¼ˆå¯èƒ½å› ä¸ºç¼ºå°‘ä¾èµ–è€Œè·³è¿‡ï¼‰
        test_run_endpoint_with_prompt_id(test_prompt_id)
        test_run_endpoint_with_recommended_prompt()
        test_run_endpoint_validation()

        print("\n" + "=" * 60)
        print("ğŸ‰ æ‰€æœ‰ E2E æµ‹è¯•å®Œæˆï¼")
        print("=" * 60)
        return True

    except AssertionError as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False
    except Exception as e:
        print(f"\nğŸ’¥ æµ‹è¯•å¼‚å¸¸: {str(e)}")
        import traceback
        traceback.print_exc()
        return False
    finally:
        # æ¸…ç†æµ‹è¯•æ•°æ®
        if test_prompt_id:
            cleanup_test_data(test_prompt_id)


if __name__ == "__main__":
    success = asyncio.run(run_all_e2e_tests())
    sys.exit(0 if success else 1)
